{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import utils \n",
    "import itertools\n",
    "import random as rand\n",
    "import math\n",
    "import copy\n",
    "sys.path.append('../')\n",
    "sys.path.insert(1, '../exp')\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import cross_validate, train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "#PostgreSQL\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# sqlgen\n",
    "import optuna\n",
    "from optuna import study\n",
    "from optuna.trial import Trial as trial\n",
    "from optuna.samplers import RandomSampler, TPESampler\n",
    "\n",
    "# graph\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "\n",
    "# featuretools\n",
    "import featuretools as ft\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345699\n",
      "Train true label: 751 Train false label: 795\n",
      "Test true label: 205 Test false label: 192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "      <th>train_comb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>213820</td>\n",
       "      <td>2066</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>213820,2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195</td>\n",
       "      <td>2286</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>195,2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>318509</td>\n",
       "      <td>4143</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>318509,4143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>323850</td>\n",
       "      <td>361</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>323850,361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>380935</td>\n",
       "      <td>3191</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>380935,3191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  age_range  gender  label   train_comb\n",
       "0   213820         2066          2       0      0  213820,2066\n",
       "1      195         2286          5       0      1     195,2286\n",
       "2   318509         4143          6       0      0  318509,4143\n",
       "3   323850          361          6       0      1   323850,361\n",
       "4   380935         3191          3       0      1  380935,3191"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../exp_data/Tmall/\"\n",
    "train_data = pd.read_csv(os.path.join(path, \"train_data.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(path, \"test_data.csv\"))\n",
    "user_log = pd.read_csv(os.path.join(path, \"user_log.csv\"))\n",
    "\n",
    "train_data = train_data.drop(train_data.columns[0], axis=1)\n",
    "train_data = train_data.drop(columns=['item_id', 'cat_id', 'brand_id', 'action_type'])\n",
    "train_data = train_data.drop_duplicates()\n",
    "\n",
    "\n",
    "test_data = test_data.drop(test_data.columns[0], axis=1)\n",
    "test_data = test_data.drop(columns=['item_id', 'cat_id', 'brand_id', 'action_type'])\n",
    "test_data = test_data.drop_duplicates()\n",
    "#user_log = user_log.drop(user_log.columns[0], axis=1)\n",
    "# data = pd.concat([train_data, test_data])\n",
    "train_data['train_comb'] = train_data['user_id'].astype(str) + ',' + train_data['merchant_id'].astype(str)\n",
    "test_data['test_comb'] = test_data['user_id'].astype(str) + ',' + test_data['merchant_id'].astype(str)\n",
    "user_log['user_log_comb'] = user_log['user_id'].astype(str) + ',' + user_log['merchant_id'].astype(str)\n",
    "\n",
    "# train_data = train_data.rename(columns={'Unnamed: 0':'train_index'})\n",
    "# test_data = test_data.rename(columns={'Unnamed: 0':'test_index'})\n",
    "user_log = user_log.rename(columns={'Unnamed: 0':'user_log_index'})\n",
    "print(len(user_log))\n",
    "print(\"Train true label:\", len(train_data[train_data['label']==1]), 'Train false label:', len(train_data[train_data['label']==0]))\n",
    "print(\"Test true label:\", len(test_data[test_data['label']==1]), 'Test false label:', len(test_data[test_data['label']==0]))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_info = pd.read_csv(os.path.join(path, \"user_info_format1.csv\"))\n",
    "# train_data = pd.read_csv(os.path.join(path, \"train_format1.csv\"))\n",
    "# train_data = train_data.merge(user_info, how='left')\n",
    "# train_data = train_data.fillna(0)\n",
    "# train_data.head()\n",
    "# train_data['train_comb'] = train_data['user_id'].astype(str) + ',' + train_data['merchant_id'].astype(str)\n",
    "# len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1546"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['train_comb'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_log_index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>action_type</th>\n",
       "      <th>item_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>user_log_comb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>323837</td>\n",
       "      <td>3420</td>\n",
       "      <td>1024</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323837,3420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>323837</td>\n",
       "      <td>1393</td>\n",
       "      <td>1030</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323837,1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>323837</td>\n",
       "      <td>1064</td>\n",
       "      <td>1030</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323837,1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>323837</td>\n",
       "      <td>1064</td>\n",
       "      <td>1030</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323837,1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>323837</td>\n",
       "      <td>1064</td>\n",
       "      <td>1030</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323837,1064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_log_index  user_id  merchant_id  time_stamp  action_type  item_id  \\\n",
       "0               0   323837         3420        1024            0        8   \n",
       "1               1   323837         1393        1030            0        7   \n",
       "2               2   323837         1064        1030            0        4   \n",
       "3               3   323837         1064        1030            0        6   \n",
       "4               4   323837         1064        1030            2        4   \n",
       "\n",
       "   cat_id  brand_id  age_range  gender user_log_comb  \n",
       "0       1        12          0       0   323837,3420  \n",
       "1       8        11          0       0   323837,1393  \n",
       "2       0        12          0       0   323837,1064  \n",
       "3       0        12          0       0   323837,1064  \n",
       "4       0        12          0       0   323837,1064  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Verify the performance of featuretools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "train_labels = train_data['label']\n",
    "train_data = train_data.drop(columns=['label'])\n",
    "test_data = test_data['label']\n",
    "test_data = test_data.drop(columns=['label'])\n",
    "\n",
    "# dataframes = {\n",
    "#     \"train_data\": (train_data, \"train_comb\"),\n",
    "#     \"user_log\": (user_log, \"user_log_index\")\n",
    "# }\n",
    "\n",
    "# relationships = [\n",
    "#     (\"train_data\", \"train_comb\", \"user_log\", \"user_log_comb\")\n",
    "# ]\n",
    "es = ft.EntitySet(\"tmall\")\n",
    "es.add_dataframe(\n",
    "    dataframe_name=\"train_data\",\n",
    "    dataframe=train_data,\n",
    "    index=\"train_comb\"\n",
    ")\n",
    "es.add_dataframe(\n",
    "    dataframe_name=\"user_log\",\n",
    "    dataframe=user_log,\n",
    "    index=\"user_log_index\"\n",
    ")\n",
    "\n",
    "es = es.add_relationship(\"train_data\", \"train_comb\", \"user_log\", \"user_log_comb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 40 features\n",
      "Elapsed: 00:00 | Progress: 100%|███████████████████████████████████████████\n",
      "Time: 0.08937692642211914\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "feature_matrix, features = ft.dfs(target_dataframe_name=\"train_data\",\n",
    "                                  agg_primitives = [\"sum\", \"min\", \"max\", \"count\", \"mean\"],\n",
    "                                  #where_primitives = [\"count\"],\n",
    "                                  trans_primitives = [],\n",
    "                                  ignore_columns={\"train_data\":['train_comb'],\n",
    "                                                  \"user_log\":['user_log_index', 'user_log_comb']},\n",
    "                                  entityset=es,\n",
    "                                  verbose=True)\n",
    "end = time.time()\n",
    "print(\"Time:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'merchant_id', 'age_range', 'gender',\n",
       "       'MAX(user_log.action_type)', 'MAX(user_log.age_range)',\n",
       "       'MAX(user_log.brand_id)', 'MAX(user_log.cat_id)',\n",
       "       'MAX(user_log.gender)', 'MAX(user_log.item_id)',\n",
       "       'MAX(user_log.merchant_id)', 'MAX(user_log.time_stamp)',\n",
       "       'MAX(user_log.user_id)', 'MEAN(user_log.action_type)',\n",
       "       'MEAN(user_log.age_range)', 'MEAN(user_log.brand_id)',\n",
       "       'MEAN(user_log.cat_id)', 'MEAN(user_log.gender)',\n",
       "       'MEAN(user_log.item_id)', 'MEAN(user_log.merchant_id)',\n",
       "       'MEAN(user_log.time_stamp)', 'MEAN(user_log.user_id)',\n",
       "       'MIN(user_log.action_type)', 'MIN(user_log.age_range)',\n",
       "       'MIN(user_log.brand_id)', 'MIN(user_log.cat_id)',\n",
       "       'MIN(user_log.gender)', 'MIN(user_log.item_id)',\n",
       "       'MIN(user_log.merchant_id)', 'MIN(user_log.time_stamp)',\n",
       "       'MIN(user_log.user_id)', 'SUM(user_log.action_type)',\n",
       "       'SUM(user_log.age_range)', 'SUM(user_log.brand_id)',\n",
       "       'SUM(user_log.cat_id)', 'SUM(user_log.gender)', 'SUM(user_log.item_id)',\n",
       "       'SUM(user_log.merchant_id)', 'SUM(user_log.time_stamp)',\n",
       "       'SUM(user_log.user_id)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.694529329279298\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier(random_state=0)\n",
    "\n",
    "scores = cross_validate(\n",
    "    clf,\n",
    "    feature_matrix,\n",
    "    train_labels.to_frame(),\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    "    return_estimator=True,\n",
    ")\n",
    "print(scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.555212378691324\n"
     ]
    }
   ],
   "source": [
    "new_train_data = train_data.drop(columns=['train_comb'])\n",
    "\n",
    "clf = XGBClassifier(random_state=0)\n",
    "\n",
    "scores = cross_validate(\n",
    "    clf,\n",
    "    new_train_data,\n",
    "    train_labels.to_frame(),\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    "    return_estimator=True,\n",
    ")\n",
    "print(scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Store table in PostragSQL\n",
    "Store train_data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': 'postgres', 'channel_binding': 'prefer', 'dbname': 'auto_fg', 'host': '127.0.0.1', 'port': '5432', 'options': '', 'sslmode': 'prefer', 'sslcompression': '0', 'sslsni': '1', 'ssl_min_protocol_version': 'TLSv1.2', 'gssencmode': 'prefer', 'krbsrvname': 'postgres', 'target_session_attrs': 'any'} \n",
      "\n",
      "You are connected to -  ('PostgreSQL 14.5 on x86_64-apple-darwin20.6.0, compiled by Apple clang version 12.0.0 (clang-1200.0.32.29), 64-bit',) \n",
      "\n",
      "tmall_log Table created successfully in PostgreSQL. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "engine = utils.store_tmall(user_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Feature Generation & Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6572015224358975\n"
     ]
    }
   ],
   "source": [
    "#valid_score, clfs = utils.model_tmall(train_data)\n",
    "y = train_data['label']\n",
    "y = y.to_frame()\n",
    "X = train_data.drop(['label'], axis=1)\n",
    "X = X.fillna(0)\n",
    "\n",
    "seeds = [0, 42, 158, 359, 1280]\n",
    "test_scores = []\n",
    "for seed in seeds:\n",
    "    clf = xgb.XGBRegressor(random_state=0)\n",
    "    clf.fit(X, y)\n",
    "    test_pred = clf.predict(test_data.drop(columns='label', axis=1))\n",
    "    test_score = metrics.roc_auc_score(test_data['label'], test_pred)\n",
    "    test_scores.append(test_score)\n",
    "print(sum(test_scores) / len(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "global copy_train_data, copy_test_data, train_data, test_data\n",
    "global trail_auc_store, trail_mi_store, train_auc_store\n",
    "\n",
    "trail_auc_store = []\n",
    "trail_mi_store = []\n",
    "train_auc_store = []\n",
    "copy_train_data = train_data\n",
    "copy_test_data = test_data\n",
    "\n",
    "global random_args_log, tpe_args_log\n",
    "global random_user_train_log, tpe_user_train_log\n",
    "\n",
    "random_args_log = {}\n",
    "tpe_args_log = {}\n",
    "random_user_train_log = {}\n",
    "tpe_user_train_log = {}\n",
    "\n",
    "global eva_global, seed_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_x is to store top features \n",
    "global res_x \n",
    "res_x = list()\n",
    "\n",
    "aggregation = ['SUM', 'MIN', 'MAX', 'COUNT', 'AVG'] \n",
    "m_attr = ['merchant_id', 'item_id', 'brand_id', 'cat_id']\n",
    "categorical = ['gender', 'age_range', 'action_type']\n",
    "numerical = ['time_stamp']\n",
    "attributes = categorical + numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_user_train(args, train_data):  \n",
    "    agg, m, lb_day, ub_day, w_cat_value_0, w_cat_value_1, w_cat_value_2 = args \n",
    "    agg = aggregation[agg]\n",
    "    m = m_attr[m]\n",
    "    \n",
    "    w_cat_value_temp = [w_cat_value_0, w_cat_value_1, w_cat_value_2] #, w_cat_value_3]\n",
    "    w_cat = []\n",
    "    w_cat_value = []\n",
    "\n",
    "    for i in range(len(categorical)):\n",
    "        if w_cat_value_temp[i] != -1:\n",
    "            w_cat.append(categorical[i])\n",
    "            w_cat_value.append(w_cat_value_temp[i])\n",
    "            \n",
    "    sql_output = utils.generate_feature_in_small_space_tmall(engine, agg, m, lb_day, ub_day, w_cat, w_cat_value) \n",
    "    w_cat_str = \"_\".join(str(w_cat[x])+'='+str(w_cat_value[x]) for x in range(len(w_cat)))\n",
    "    new_feature = pd.DataFrame(sql_output, columns = ['user_id', agg+'('+m+')_'+w_cat_str+'_'+'lb_day='+str(lb_day)+\"_ub_day=\"+str(ub_day)]) #+'='+g_cat\n",
    "    new_feature = new_feature.astype('float')\n",
    "    new_train_data = train_data.merge(new_feature, how='left')\n",
    "    \n",
    "    return new_train_data, args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an objective function\n",
    "def objective(trial):\n",
    "    agg = trial.suggest_categorical('agg', np.array([i for i in range(len(aggregation))]))\n",
    "    m = trial.suggest_categorical('m', np.array([i for i in range(len(m_attr))]))  \n",
    "    lb_day = trial.suggest_categorical('lb_day', sorted_time[0: math.ceil(len(sorted_time)/2)])\n",
    "    ub_day = trial.suggest_categorical('ub_day', sorted_time[math.ceil(len(sorted_time)/2)+1: -1])\n",
    "    w_cat_value_0 = trial.suggest_categorical('w_cat_value_0', np.append(user_log[categorical[0]].unique(), [-1], 0))\n",
    "    w_cat_value_1 = trial.suggest_categorical('w_cat_value_1', np.append(user_log[categorical[1]].unique(), [-1], 0))\n",
    "    w_cat_value_2 = trial.suggest_categorical('w_cat_value_2', np.append(user_log[categorical[2]].unique(), [-1], 0))\n",
    "\n",
    "    args = [agg, m, lb_day, ub_day, w_cat_value_0, w_cat_value_1, w_cat_value_2] #, w_cat_value_3]\n",
    "    new_train_data, args = update_user_train(args, train_data)\n",
    "    score, _ = utils.model_tmall(new_train_data)\n",
    "    \n",
    "    #是不是不应该这么粗暴地去重？？\n",
    "    # for x in res_x:\n",
    "    #     if args == x:\n",
    "    #         score -= 0.2\n",
    "    #         break\n",
    "        \n",
    "    print(args, \" auc: \", score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a NEW function with mutual information\n",
    "\n",
    "def mi(trial):\n",
    "    agg = trial.suggest_categorical('agg', np.array([i for i in range(len(aggregation))]))\n",
    "    m = trial.suggest_categorical('m', np.array([i for i in range(len(m_attr))]))  \n",
    "    lb_day = trial.suggest_categorical('lb_day', sorted_time[0: math.ceil(len(sorted_time)/2)])\n",
    "    ub_day = trial.suggest_categorical('ub_day', sorted_time[math.ceil(len(sorted_time)/2)+1: -1])\n",
    "    w_cat_value_0 = trial.suggest_categorical('w_cat_value_0', np.append(user_log[categorical[0]].unique(), [-1], 0))\n",
    "    w_cat_value_1 = trial.suggest_categorical('w_cat_value_1', np.append(user_log[categorical[1]].unique(), [-1], 0))\n",
    "    w_cat_value_2 = trial.suggest_categorical('w_cat_value_2', np.append(user_log[categorical[2]].unique(), [-1], 0))\n",
    "\n",
    "    args = [agg, m, lb_day, ub_day, w_cat_value_0, w_cat_value_1, w_cat_value_2] #, w_cat_value_3]\n",
    "    new_train_data, args = update_user_train(args, train_data)\n",
    "\n",
    "    mi_matrix = mutual_info_classif(new_train_data.fillna(0), new_train_data['label'], random_state=0)\n",
    "    mi_score = mi_matrix[-1]\n",
    "    \n",
    "    #是不是不应该这么粗暴地去重？？\n",
    "    # for x in res_x:\n",
    "    #     if args == x:\n",
    "    #         mi_score = 0\n",
    "    #         break\n",
    "            \n",
    "    print(args, \"MI:\", mi_score)\n",
    "    return mi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sampling \n",
    "def evaluate(trial_arr, mi_log, train_size):\n",
    "    x_features = pd.DataFrame()\n",
    "    x_features['index'] = range(0, len(mi_log))\n",
    "    x_features['mi'] = mi_log\n",
    "    x_features['agg'] = [trial_arr[i]['agg'] for i in range(len(trial_arr))]\n",
    "    x_features['m'] = [trial_arr[i]['m'] for i in range(len(trial_arr))]\n",
    "    x_features['lb_day'] = [trial_arr[i]['lb_day'] for i in range(len(trial_arr))]\n",
    "    x_features['ub_day'] = [trial_arr[i]['ub_day'] for i in range(len(trial_arr))]\n",
    "    x_features['w_cat_value_0'] = [trial_arr[i]['w_cat_value_0'] for i in range(len(trial_arr))]\n",
    "    x_features['w_cat_value_1'] = [trial_arr[i]['w_cat_value_1'] for i in range(len(trial_arr))]\n",
    "    x_features['w_cat_value_2'] = [trial_arr[i]['w_cat_value_2'] for i in range(len(trial_arr))]\n",
    "\n",
    "    print(x_features.shape)\n",
    "    x_train, x_test = train_test_split(x_features, train_size=200, random_state=0)\n",
    "    \n",
    "    y_acc = []\n",
    "    for index, feature in x_train.iterrows():\n",
    "        args = [int(feature['agg']),\n",
    "               int(feature['m']),\n",
    "               int(feature['lb_day']),\n",
    "               int(feature['ub_day']),\n",
    "               int(feature['w_cat_value_0']),\n",
    "               int(feature['w_cat_value_1']),\n",
    "               int(feature['w_cat_value_2'])] \n",
    "        new_train_data, args = update_user_train(args, train_data)\n",
    "        \n",
    "        y_acc.append(utils.model_tmall(new_train_data)[0])\n",
    "\n",
    "    y_train = pd.DataFrame()\n",
    "    y_train['index'] = x_train['index']\n",
    "    y_train['label'] = y_acc\n",
    "\n",
    "    global clf\n",
    "    clf =  RandomForestRegressor(random_state=0) #LinearRegression()\n",
    "    clf.fit(x_train[['mi']], y_train['label'])\n",
    "    \n",
    "    global estimated_accuracy\n",
    "    estimated_accuracy = clf.predict(x_features[['mi']])\n",
    "    predict_y = pd.DataFrame()\n",
    "    predict_y['index'] = range(0, len(mi_log))\n",
    "    predict_y['label'] = estimated_accuracy\n",
    "    \n",
    "    for index, row in y_train.iterrows():\n",
    "        predict_y.loc[predict_y['index'] == row['index'], 'label'] = row['label']\n",
    "    \n",
    "    best_trail_index = y_train.nlargest(1, ['label']).index[0]\n",
    "    train_auc_store.append(predict_y['label'].to_numpy())\n",
    "    return predict_y['label'].to_numpy(), best_trail_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 5\n",
    "\n",
    "n_calls = [1500]\n",
    "random_state_arr = [0] \n",
    "\n",
    "for n_call in n_calls:\n",
    "    tpe_args_log[n_call] = {}\n",
    "    tpe_user_train_log[n_call] = {}\n",
    "    for seed in random_state_arr:\n",
    "        tpe_args_log[n_call][seed] = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLGEN - Opt3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Test ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-21 21:57:24,033]\u001b[0m A new study created in memory with name: no-name-39b460c9-7edc-4cfe-bda9-d4a393ade105\u001b[0m\n",
      "\u001b[33m[W 2022-09-21 21:57:24,039]\u001b[0m Trial 0 failed because of the following error: NameError(\"name 'sorted_time' is not defined\")\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danruiqi/.pyenv/versions/3.9.6/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/mw/_z63l58x77q255c57knqd4dr0000gn/T/ipykernel_45313/1752518.py\", line 5, in objective\n",
      "    lb_day = trial.suggest_categorical('lb_day', sorted_time[0: math.ceil(len(sorted_time)/2)])\n",
      "NameError: name 'sorted_time' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trails: 1500\n",
      "seed: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sorted_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m tpe_result \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m     19\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     20\u001b[0m     sampler\u001b[38;5;241m=\u001b[39mTPESampler(n_startup_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, seed\u001b[38;5;241m=\u001b[39mseed)) \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# tpe_result.optimize(objective, n_trials=eva, \u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#                     mi_initializer=mi, evaluate=evaluate, mi_init_trails=1000, train_size=100)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mtpe_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meva\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m tpe_result\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      3\u001b[0m agg \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124magg\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39marray([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(aggregation))]))\n\u001b[1;32m      4\u001b[0m m \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39marray([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(m_attr))]))  \n\u001b[0;32m----> 5\u001b[0m lb_day \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlb_day\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43msorted_time\u001b[49m[\u001b[38;5;241m0\u001b[39m: math\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;28mlen\u001b[39m(sorted_time)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)])\n\u001b[1;32m      6\u001b[0m ub_day \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mub_day\u001b[39m\u001b[38;5;124m'\u001b[39m, sorted_time[math\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;28mlen\u001b[39m(sorted_time)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      7\u001b[0m w_cat_value_0 \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_cat_value_0\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mappend(user_log[categorical[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique(), [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_time' is not defined"
     ]
    }
   ],
   "source": [
    "eva_store_optuna = []\n",
    "\n",
    "start = time.time()\n",
    "for eva in n_calls:\n",
    "    print(\"trails:\", eva)\n",
    "    eva_global = eva\n",
    "    seed_store = []\n",
    "    for seed in random_state_arr:\n",
    "        seed_global = seed\n",
    "        global train_data, res_x \n",
    "        res_optuna_lst = []\n",
    "        res_optuna_fun = []\n",
    "        res_x = list()\n",
    "        train_data = copy_train_data\n",
    "        print(\"seed:\", seed)\n",
    "\n",
    "        for i in range(top):\n",
    "            tpe_result = study.create_study(\n",
    "                direction=\"maximize\", \n",
    "                sampler=TPESampler(n_startup_trials=20, seed=seed)) #\n",
    "            # tpe_result.optimize(objective, n_trials=eva, \n",
    "            #                     mi_initializer=mi, evaluate=evaluate, mi_init_trails=1000, train_size=100)\n",
    "            tpe_result.optimize(objective, n_trials=eva)\n",
    "            \n",
    "            best_trial = []\n",
    "            for key, value in tpe_result.best_trial.params.items():\n",
    "                best_trial.append(value)\n",
    "            res_x.append(best_trial)\n",
    "\n",
    "            train_data, args = update_user_train(best_trial, train_data)\n",
    "            res_optuna_lst.append(tpe_result.best_trial.params)\n",
    "            res_optuna_fun.append(tpe_result.best_value)\n",
    "\n",
    "            print(tpe_result.best_trial.params, tpe_result.best_value)\n",
    "            print(train_data.shape)\n",
    "            tpe_args_log[eva][seed].append(args)\n",
    "        seed_store.append(res_optuna_fun)\n",
    "        tpe_user_train_log[eva][seed] = train_data\n",
    "        \n",
    "    eva_store_optuna.append(seed_store)\n",
    "end = time.time()\n",
    "print(\"Time:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tmall(user_train):\n",
    "    y = user_train['label']\n",
    "    y = y.to_frame()\n",
    "    X = user_train.drop(['label'], axis=1)\n",
    "    X = X.fillna(0)\n",
    "\n",
    "    clf = xgb.XGBRegressor(random_state=0)\n",
    "    auc = cross_validate(clf, X, y, cv=5,scoring=('roc_auc'), return_train_score=True, n_jobs=-1, return_estimator=True)\n",
    "    valid_auc = auc['test_score'].mean()\n",
    "    train_auc = auc['train_score'].mean()\n",
    "\n",
    "    return train_auc, valid_auc, auc['estimator'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_auc = {}\n",
    "train_auc = {}\n",
    "valid_auc = {}\n",
    "for n_calls in tpe_args_log:\n",
    "    for seed in tpe_args_log[n_calls]:\n",
    "        test_auc[seed] = []\n",
    "        train_auc[seed] = []\n",
    "        valid_auc[seed] = []\n",
    "        train_data = copy_train_data\n",
    "        test_data = copy_test_data\n",
    "        \n",
    "        # Default AUC without new features\n",
    "        train, valid, clf = model_tmall(train_data)\n",
    "        train_auc[seed].append(train)\n",
    "        valid_auc[seed].append(valid)\n",
    "        test_pred = clf.predict(test_data.drop(columns='label', axis=1))\n",
    "        test_auc[seed].append(metrics.roc_auc_score(test_data['label'], test_pred))\n",
    "        for args in tpe_args_log[n_calls][seed]:\n",
    "            test_data, config = update_user_train(args, test_data)\n",
    "            train_data, config = update_user_train(args, train_data)\n",
    "            train, valid, clf = model_tmall(train_data)\n",
    "            train_auc[seed].append(train)\n",
    "            valid_auc[seed].append(valid)\n",
    "            \n",
    "            test_data = test_data.fillna(0)\n",
    "            test_pred = clf.predict(test_data.drop(columns='label', axis=1))\n",
    "            test_auc[seed].append(metrics.roc_auc_score(test_data['label'], test_pred))\n",
    "train_auc, valid_auc, test_auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
